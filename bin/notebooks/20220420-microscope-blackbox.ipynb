{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to try to learn a CNN that reproduces the signal processing of a microscope. I'm going to train on some images that I believe are \"bags of GFP\" -- Colleen's IDRs and Zelda C-terminal fragments. I measure the concentration of these via the standard candles, that means I can make a reasonable simulation of the \"true image\" — just n fluors randomly distributed within the mask. I can make a lot of sims for each real image. The CNN needs to output an n X n X n image, the loss function is some simple measure of pixel intensity difference (I think mean difference per non-zero pixel? Obvi can try multiple things).\n",
    "\n",
    "Workflow:\n",
    "\n",
    "1. Make an initial training set (simulations of real c-terminal nuclei with 80 nM free)\n",
    "2. Design a 1 conv layer network to test (just get it to ouput proper size and test loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import flymovie as fm\n",
    "import cnn_models.siamese_cnn as cn\n",
    "import cnn_models.evaluate_models as ev\n",
    "from flymovie.simnuc import Sim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from importlib import reload\n",
    "from sklearn.manifold import TSNE\n",
    "import scipy.ndimage as ndi\n",
    "import skimage as ski\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
    "from tensorflow.keras import Model\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "imfolder = '/Users/michaelstadler/Bioinformatics/Projects/rpb1/data/blackbox/reals/'\n",
    "outfolder = '/Users/michaelstadler/Bioinformatics/Projects/rpb1/data/blackbox/sims/'\n",
    "imfile = 'zld-cterm_20220321-zld-cterm-gfp-em1-01_0_1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = fm.load_pickle(os.path.join(imfolder, imfile))\n",
    "mask = ndi.morphology.binary_erosion(np.where(im > 0, 1, 0), structure=np.ones((1,7,7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imfile in os.listdir(imfolder):\n",
    "    if imfile[0] == '.':\n",
    "        continue\n",
    "    im = fm.load_pickle(os.path.join(imfolder, imfile))\n",
    "    mask = ndi.morphology.binary_erosion(np.where(im > 0, 1, 0), structure=np.ones((1,7,7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imfile in os.listdir(imfolder):\n",
    "    if imfile[0] == '.':\n",
    "        continue\n",
    "    im = fm.load_pickle(os.path.join(imfolder, imfile))\n",
    "    mask = ndi.morphology.binary_erosion(np.where(im > 0, 1, 0), structure=np.ones((1,7,7)))\n",
    "\n",
    "    for _ in range(1):\n",
    "        leader = ''.join(random.choice(string.ascii_letters) for i in range(3)) + '_'\n",
    "        sim = Sim(mask, 250,85)\n",
    "        nmolecules = round(sim.conc_to_nmolecules(80))\n",
    "        sim.add_n_objects(nmolecules, 1, 1, 1)\n",
    "        filename = os.path.join(outfolder, leader + imfile)\n",
    "        fm.save_pickle(sim.im, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals_folder = '/Users/michaelstadler/Bioinformatics/Projects/rpb1/data/blackbox/reals/'\n",
    "sims_folder = '/Users/michaelstadler/Bioinformatics/Projects/rpb1/data/blackbox/sims/'\n",
    "batch_size = 32\n",
    "image_shape = (34,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.data.Dataset.from_tensor_slices(anchor_files)\n",
    "\n",
    "sim_files1 = os.listdir(sims_folder)\n",
    "sim_files2 = []\n",
    "real_files = []\n",
    "for f in sim_files1:\n",
    "    if f[0] == '.':\n",
    "        continue\n",
    "\n",
    "    splits = f.split('_')\n",
    "    real_file = '_'.join(splits[1:])\n",
    "    sim_files2.append(os.path.join(sims_folder, f))\n",
    "    real_files.append(os.path.join(reals_folder, real_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(im_sim, im_real):\n",
    "    [sim,] = tf.py_function(cn.preprocess_image,[im_sim,],[tf.float32,])\n",
    "    [real,] = tf.py_function(cn.preprocess_image,[im_real,],[tf.float32,])\n",
    "    #sim = tf.squeeze(sim)\n",
    "    #real = tf.squeeze(real)\n",
    "    return sim, real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sim_ds = tf.data.Dataset.from_tensor_slices((sim_files2, real_files))\n",
    "#real_ds = tf.data.Dataset.from_tensor_slices(real_files)\n",
    "\n",
    "sim_ds = sim_ds.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#real_ds = real_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "sim_ds = sim_ds.batch(batch_size, drop_remainder=False)\n",
    "#real_ds = real_ds.batch(batch_size, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elem = np.product(image_shape)\n",
    "img_input = layers.Input(shape=image_shape + (1,)) # Channels last.\n",
    "#x = layers.ZeroPadding3D(padding=(5, 10, 10), name='psf_pad')(img_input)\n",
    "x = layers.Conv3D(1, (10,20,20),\n",
    "        strides=(1, 1, 1),\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal',\n",
    "        name='psf')(img_input)\n",
    "\n",
    "#x = layers.ZeroPadding3D(padding=(3, 3, 3), name='conv1_pad')(x)\n",
    "\"\"\"\n",
    "x = layers.Conv3D(64, (3,3,3),\n",
    "        strides=(1, 1, 1),\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal',\n",
    "        name='conv1')(x)\n",
    "\"\"\"\n",
    "class NoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(NoiseLayer, self).__init__()\n",
    "\t\t\n",
    "    def call(self, x_input, training=False):\n",
    "        x = tf.keras.layers.GaussianNoise(0.1)(x_input)\n",
    "        return x\n",
    "x = NoiseLayer()(x)\n",
    "#x = layers.Flatten()(x)\n",
    "#x = layers.Dense(num_elem, activation='linear')(x)\n",
    "output = tf.math.reduce_sum(x, axis=-1)\n",
    "#x = tf.keras.backend.sum(x, axis=-1)\n",
    "#x = layers.Reshape(tuple([64]) + image_shape)(x)\n",
    "model = Model(img_input, output, name=\"Embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ds = tf.data.Dataset.from_tensor_slices((sim_files2, real_files))\n",
    "\n",
    "sim_ds = sim_ds.map(preprocess_images, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "sim_ds = sim_ds.batch(batch_size, drop_remainder=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.0267\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.0172\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.0114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x181de2a30>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset = tf.data.Dataset.zip((sim_ds, real_ds))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss=tf.keras.losses.mean_squared_error)\n",
    "model.fit(sim_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 28s 28s/step - loss: 0.0091\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.0094\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.0111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x181ada460>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sim_ds, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = []\n",
    "for i in sim_ds:\n",
    "    sims.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f999cd188c704a48833512b823aca56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=10, options=('Reds', 'plasma', 'gray', 'magma', 'inf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = model(np.expand_dims(sims[0][0][1], axis=0))\n",
    "\n",
    "fm.viewer(t.numpy() * 1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = model.layers[1]\n",
    "w = l.get_weights()[0]\n",
    "w = np.squeeze(w)\n",
    "fm.viewer(w * 1_000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824fd0fac02f48e185ded9447a40ae3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=10, options=('Reds', 'plasma', 'gray', 'magma', 'inf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = l.get_weights()[0]\n",
    "w = np.squeeze(w)\n",
    "fm.viewer(w * 1_000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    #x_nz = x[x > 0]\n",
    "    x_nz = x\n",
    "    #return x\n",
    "    return (x - np.min(x_nz)) / (np.max(x_nz) - np.min(x_nz))\n",
    "\n",
    "real = fm.load_pickle('/Users/michaelstadler/Bioinformatics/Projects/rpb1/data/blackbox/reals/zld-cterm_20220321-zld-cterm-gfp-em1-01_0_1.pkl')\n",
    "real = norm(real)\n",
    "mask = ndi.morphology.binary_erosion(np.where(real > 0, 1, 0), structure=np.ones((1,7,7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm.load_pickle('/Users/michaelstadler/Bioinformatics/Projects/rpb1/data/blackbox/sims/GUB_zld-cterm_20220321-zld-cterm-gfp-em1-01_0_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 25, 25)\n",
      "(8, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "kernel = fm.load_pickle('/Users/michaelstadler/Bioinformatics/Projects/rpb1/PSFs/psf_20220210_21x25x25pixels_100x50x50voxel.pkl')\n",
    "print(kernel.shape)\n",
    "kernel = ndi.zoom(kernel, (100/250, 50/85, 50/85))\n",
    "print(kernel.shape)\n",
    "kernel = kernel / np.sum(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ndi.convolve(sim, kernel)\n",
    "cv = norm(cv)\n",
    "n = np.random.normal(0, 0.4, size=cv.shape)\n",
    "n = np.where(mask > 0, n, 0)\n",
    "cv = cv + n\n",
    "cv = norm(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e19216311414787ba661effe8b96d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=10, options=('Reds', 'plasma', 'gray', 'magma', 'inf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fm.viewer([cv * 1000, real * 1000],5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4f5185e3bc4c21b270a8c9313b9bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=10, options=('Reds', 'plasma', 'gray', 'magma', 'inf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fm.viewer((cv - real) * 1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = real - cv\n",
    "res = res[mask > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(res, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "x = scipy.stats.norm(loc=-0.2, scale=0.15)\n",
    "#plt.plot(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.random.normal(0, 0.15, size=(34,100,100))\n",
    "n = n - np.min(n)\n",
    "n = np.where(mask > 0, n, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647144fa9bed4934aa1bb7937fa3a25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=10, options=('Reds', 'plasma', 'gray', 'magma', 'inf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fm.viewer(n * 1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa362097aeb4c79bbef48c72d0fa618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=10, options=('Reds', 'plasma', 'gray', 'magma', 'inf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3e084a8beb2490aaff2c1833c88acc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=10, options=('Reds', 'plasma', 'gray', 'magma', 'inf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/Users/michaelstadler/Bioinformatics/Projects/rpb1/results/trained_models/blackbox')\n",
    "\n",
    "im = fm.load_pickle('/Users/michaelstadler/Bioinformatics/Projects/rpb1/data/blackbox/sims/Jpb_zld-cterm_20220321-zld-cterm-gfp-em1-01_0_5.pkl')\n",
    "\n",
    "x = np.expand_dims(im, axis=-1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "m = model(x)\n",
    "\n",
    "fm.viewer(m.numpy() * 1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5941ab3feda449869da30ebfe431da77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=10, options=('Reds', 'plasma', 'gray', 'magma', 'inf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('/Users/michaelstadler/Bioinformatics/Projects/rpb1/results/trained_models/blackbox2')\n",
    "\n",
    "im = fm.load_pickle('/Users/michaelstadler/Bioinformatics/Projects/rpb1/data/blackbox/sims/Jpb_zld-cterm_20220321-zld-cterm-gfp-em1-01_0_5.pkl')\n",
    "\n",
    "x = np.expand_dims(im, axis=-1)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "m = model(x)\n",
    "\n",
    "fm.viewer(m.numpy() * 1000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<property object at 0x17cc78590>\n"
     ]
    }
   ],
   "source": [
    "print(tf.keras.layers.Conv3D.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Embedding\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 34, 100, 100, 1)] 0         \n",
      "_________________________________________________________________\n",
      "psf (Conv3D)                 (None, 34, 100, 100, 1)   1801      \n",
      "_________________________________________________________________\n",
      "conv1 (Conv3D)               (None, 34, 100, 100, 64)  1792      \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLamb (None, 34, 100, 100)      0         \n",
      "=================================================================\n",
      "Total params: 3,593\n",
      "Trainable params: 3,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e372816e4ed8f4776be7691c42762f9e24664f8c81a636e19b7b5da78d6a9ebf"
  },
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
