{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import flymovie as fm\n",
    "import cnn_models\n",
    "import cnn_models.siamese_cnn as cn\n",
    "import cnn_models.evaluate_models as ev\n",
    "from flymovie.simnuc import Sim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from fpdf import FPDF\n",
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import scipy.spatial\n",
    "import scipy.ndimage as ndi\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_models.siamese_cnn import preprocess_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_models.siamese_cnn import preprocess_image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "#---------------------------------------------------------------------------\n",
    "def get_target_shape(dir_):\n",
    "    \"\"\"Retrieve the image target size.\"\"\"\n",
    "    left = dir_ / 'left'\n",
    "    imfile = os.listdir(left)[-1]\n",
    "    impath = os.path.join(left, imfile)\n",
    "    with open(impath, 'rb') as file:\n",
    "        im = pickle.load(file)\n",
    "\n",
    "    shape = im.shape\n",
    "    return shape\n",
    "\n",
    "def make_im_param_inputs(folder, batch_size=32):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def get_files_params(subfolder):\n",
    "        files = os.listdir(subfolder)\n",
    "        files = [x if x[0] != '.' else None for x in files]\n",
    "        n_params = len(files[0].split('_')) - 2\n",
    "        params = np.zeros((0, n_params))\n",
    "        for f in files:\n",
    "            p = f.split('_')[1:-1]\n",
    "            p = [float(x) for x in p]\n",
    "            p = np.expand_dims(np.array(p), axis=0)\n",
    "            params = np.vstack((params, p))\n",
    "        files = [os.path.join(subfolder, x) for x in files]\n",
    "        return files, list(params)\n",
    "\n",
    "    def preprocess(file, paramset):\n",
    "        [im,] = tf.py_function(preprocess_image,[file,],[tf.float32,])\n",
    "        return im, paramset\n",
    "\n",
    "    # Set up input directories.\n",
    "    cache_dir=folder\n",
    "    left_path = cache_dir / \"left\"\n",
    "    right_path = cache_dir / \"right\"\n",
    "    \n",
    "    files_l, params_l = get_files_params(left_path)\n",
    "    files_r, params_r = get_files_params(right_path)\n",
    "    files = files_l + files_r\n",
    "    params = params_l + params_r\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((files, params))\n",
    "    dataset = dataset.shuffle(buffer_size=len(files))\n",
    "\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(32)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "    # Create datasets from these sorted files. These are in order and match in pairs.\n",
    "    \n",
    "ds = make_im_param_inputs(Path('/Users/michaelstadler/Bioinformatics/Projects/rpb1/results/testsims_uPoNivMJ_10'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_shape = get_target_shape(cache_dir)\n",
    "base_cnn = cn.make_base_cnn_3d(target_shape, 'base_cnn', nlayers=8)\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(9)(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(base_cnn.input, output, name=\"Model\")\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    metrics=[\"acc\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 - 12s - loss: 3737.2253 - acc: 0.0500\n",
      "Epoch 2/5\n",
      "1/1 - 9s - loss: 11794.1465 - acc: 0.2000\n",
      "Epoch 3/5\n",
      "1/1 - 9s - loss: 6266.0391 - acc: 0.3500\n",
      "Epoch 4/5\n",
      "1/1 - 9s - loss: 6394.3345 - acc: 0.3500\n",
      "Epoch 5/5\n",
      "1/1 - 9s - loss: 5369.0830 - acc: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x184c4e850>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    ds,\n",
    "    epochs=5,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial\n",
    "\n",
    "num_to_sample = 100_000\n",
    "files = np.arange(100_000)\n",
    "a1 = np.random.random(9)\n",
    "a2 = np.random.random(9)\n",
    "rs = np.random.RandomState()\n",
    "for _ in range(num_to_sample):\n",
    "    rs = np.random.RandomState()\n",
    "    rs.choice(files)\n",
    "    rs.choice(files)\n",
    "    (a1 - a2) / a1\n",
    "    (a1 - a2) / a1\n",
    "    dist = scipy.spatial.distance.euclidean(a1, a2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266f04b9fa43429d8c44feb6a7653611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=8, options=('viridis', 'inferno', 'magma', 'Gators',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, val = cn.make_triplet_inputs('/Users/michaelstadler/Bioinformatics/Projects/rpb1/results/testsims_uPoNivMJ/filetriplets_0.0_4.0_5_vLz.csv.gz', batch_size=50, epoch_size=50, rotate=False)\n",
    "ev.visualize_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ce00b9448046319d2a0c4f6abd171c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Color', index=8, options=('viridis', 'inferno', 'magma', 'Gators',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, val = cn.make_triplet_inputs('/Users/michaelstadler/Bioinformatics/Projects/rpb1/results/testsims_uPoNivMJ_10/filetriplets_0.0_100.0_5_SCc.csv', batch_size=50, epoch_size=50, rotate=False)\n",
    "ev.visualize_batch(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.random.random((20,10))\n",
    "scaled = (a - a.mean(axis=0)) / a.std(axis=0)\n",
    "len(list(scaled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.random.randint(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "nfiles = 10\n",
    "filenames = []\n",
    "for _ in range(nfiles):\n",
    "    filename = ''.join([random.choice(string.ascii_letters) for i in range(3)])\n",
    "    for i in range(8):\n",
    "        n = random.choice([1,2,3,4,5,6,7,8,9])\n",
    "        filename = filename + '_' + str(n)\n",
    "    filename = filename + '_rep0.pkl'\n",
    "    filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fm.load_pickle(\"/Users/michaelstadler/Bioinformatics/Projects/rpb1/results/testsims_uPoNivMJ_10/filetriplets_0.0_100.0_FMV.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e372816e4ed8f4776be7691c42762f9e24664f8c81a636e19b7b5da78d6a9ebf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
